{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0-alpha0\n",
      "sys.version_info(major=3, minor=7, micro=6, releaselevel='final', serial=0)\n",
      "matplotlib 3.2.0\n",
      "numpy 1.16.2\n",
      "pandas 1.0.1\n",
      "sklearn 0.20.3\n",
      "tensorflow 2.0.0-alpha0\n",
      "tensorflow.python.keras.api._v2.keras 2.2.4-tf\n",
      "scipy 1.4.1\n"
     ]
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import scipy.stats\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "print(tf.__version__)\n",
    "print(sys.version_info)\n",
    "for module in mpl, np, pd, sklearn, tf, keras,scipy:\n",
    "    print(module.__name__, module.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "housing = fetch_california_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11610, 8) (11610,)\n",
      "(3870, 8) (3870,)\n",
      "(5160, 8) (5160,)\n"
     ]
    }
   ],
   "source": [
    "# 分割数据集的工具\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 分割训练集和测试集，比例为3:1\n",
    "x_train_all, x_test, y_train_all, y_test = train_test_split(\n",
    "    housing.data, housing.target, random_state = 7) \n",
    "# 分割训练集和开发集，比例是3:1，总的比例是9:3:4\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(\n",
    "    x_train_all, y_train_all, random_state = 11)\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_valid.shape, y_valid.shape)\n",
    "print(x_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 标准归一化工具\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_valid_scaled = scaler.transform(x_valid)\n",
    "x_test_scaled = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 100us/sample - loss: 4.3369 - val_loss: 3.5388\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 2.7588 - val_loss: 2.3128\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 1.8741 - val_loss: 1.6719\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 1.4357 - val_loss: 1.3510\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 1s 82us/sample - loss: 1.1960 - val_loss: 1.1534\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 1s 113us/sample - loss: 1.0361 - val_loss: 1.0124\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.9217 - val_loss: 0.9095\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.8375 - val_loss: 0.8349\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.7763 - val_loss: 0.7803\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.7316 - val_loss: 0.7401\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.6987 - val_loss: 0.7118\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.6745 - val_loss: 0.6909\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 1s 79us/sample - loss: 0.6562 - val_loss: 0.6750\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.6421 - val_loss: 0.6627\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.6308 - val_loss: 0.6528\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.6216 - val_loss: 0.6447\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.6138 - val_loss: 0.6378\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.6070 - val_loss: 0.6316\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.6009 - val_loss: 0.6262\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.5955 - val_loss: 0.6208\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.5905 - val_loss: 0.6160\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.5858 - val_loss: 0.6114\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.5814 - val_loss: 0.6072\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5772 - val_loss: 0.6026\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.5731 - val_loss: 0.5987\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.5693 - val_loss: 0.5945\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.5655 - val_loss: 0.5907\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 1s 81us/sample - loss: 0.5619 - val_loss: 0.5868\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 1s 84us/sample - loss: 0.5584 - val_loss: 0.5830\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 1s 100us/sample - loss: 0.5550 - val_loss: 0.5791\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 1s 100us/sample - loss: 0.5517 - val_loss: 0.5756\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 1s 88us/sample - loss: 0.5486 - val_loss: 0.5721\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.5454 - val_loss: 0.5687\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.5423 - val_loss: 0.5651\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.5394 - val_loss: 0.5619\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.5365 - val_loss: 0.5587\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.5337 - val_loss: 0.5555\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.5309 - val_loss: 0.5529\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.5283 - val_loss: 0.5498\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.5257 - val_loss: 0.5469\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.5231 - val_loss: 0.5439\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 1s 95us/sample - loss: 0.5206 - val_loss: 0.5413\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 1s 89us/sample - loss: 0.5182 - val_loss: 0.5384\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.5157 - val_loss: 0.5360\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.5135 - val_loss: 0.5334\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.5112 - val_loss: 0.5309\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.5090 - val_loss: 0.5284\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.5068 - val_loss: 0.5260\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.5047 - val_loss: 0.5238\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.5026 - val_loss: 0.5216\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.5006 - val_loss: 0.5192\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.4986 - val_loss: 0.5171\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.4967 - val_loss: 0.5149\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.4947 - val_loss: 0.5128\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4929 - val_loss: 0.5107\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.4910 - val_loss: 0.5089\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.4893 - val_loss: 0.5069\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4875 - val_loss: 0.5049\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4858 - val_loss: 0.5030\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4841 - val_loss: 0.5013\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4825 - val_loss: 0.4994\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4809 - val_loss: 0.4976\n",
      "3870/3870 [==============================] - 0s 20us/sample - loss: 0.4473\n",
      "7740/7740 [==============================] - 0s 20us/sample - loss: 0.4797\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 74us/sample - loss: 4.3620 - val_loss: 3.5162\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 2.6911 - val_loss: 2.2425\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 1.8116 - val_loss: 1.6049\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 1.3672 - val_loss: 1.2803\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 1.1309 - val_loss: 1.0981\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.9821 - val_loss: 0.9828\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.8901 - val_loss: 0.9077\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.8251 - val_loss: 0.8560\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.7801 - val_loss: 0.8202\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.7488 - val_loss: 0.7950\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.7262 - val_loss: 0.7765\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.7093 - val_loss: 0.7626\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.6962 - val_loss: 0.7513\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.6854 - val_loss: 0.7420\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.6763 - val_loss: 0.7339\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.6685 - val_loss: 0.7267\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.6614 - val_loss: 0.7202\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.6551 - val_loss: 0.7141\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.6492 - val_loss: 0.7084\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.6437 - val_loss: 0.7029\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.6383 - val_loss: 0.6976\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.6331 - val_loss: 0.6925\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.6282 - val_loss: 0.6876\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.6234 - val_loss: 0.6826\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.6188 - val_loss: 0.6779\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.6143 - val_loss: 0.6732\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.6100 - val_loss: 0.6685\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.6057 - val_loss: 0.6639\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.6015 - val_loss: 0.6594\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.5975 - val_loss: 0.6550\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.5936 - val_loss: 0.6507\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.5897 - val_loss: 0.6465\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.5860 - val_loss: 0.6423\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.5822 - val_loss: 0.6382\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.5786 - val_loss: 0.6342\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.5750 - val_loss: 0.6303\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.5716 - val_loss: 0.6265\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.5682 - val_loss: 0.6228\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.5648 - val_loss: 0.6192\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.5616 - val_loss: 0.6156\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.5585 - val_loss: 0.6121\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.5555 - val_loss: 0.6085\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.5524 - val_loss: 0.6050\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.5495 - val_loss: 0.6018\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.5466 - val_loss: 0.5985\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.5438 - val_loss: 0.5954\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.5411 - val_loss: 0.5922\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.5384 - val_loss: 0.5891\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.5357 - val_loss: 0.5861\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.5332 - val_loss: 0.5833\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.5307 - val_loss: 0.5803\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.5281 - val_loss: 0.5775\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.5258 - val_loss: 0.5746\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5233 - val_loss: 0.5719\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.5209 - val_loss: 0.5694\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.5187 - val_loss: 0.5666\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5164 - val_loss: 0.5640\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.5142 - val_loss: 0.5615\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.5121 - val_loss: 0.5590\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.5099 - val_loss: 0.5565\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.5079 - val_loss: 0.5542\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.5058 - val_loss: 0.5517\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.5038 - val_loss: 0.5493\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.5018 - val_loss: 0.5471\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.4999 - val_loss: 0.5447\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.4980 - val_loss: 0.5425\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4962 - val_loss: 0.5403\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.4943 - val_loss: 0.5381\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.4925 - val_loss: 0.5359\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.4907 - val_loss: 0.5338\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4890 - val_loss: 0.5317\n",
      "Epoch 72/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4873 - val_loss: 0.5297\n",
      "Epoch 73/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.4856 - val_loss: 0.5278\n",
      "Epoch 74/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4840 - val_loss: 0.5259\n",
      "Epoch 75/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4823 - val_loss: 0.5239\n",
      "3870/3870 [==============================] - 0s 22us/sample - loss: 0.4880\n",
      "7740/7740 [==============================] - 0s 20us/sample - loss: 0.4812\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 78us/sample - loss: 4.0194 - val_loss: 3.2681\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 1s 72us/sample - loss: 2.4295 - val_loss: 2.1215\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 1.6306 - val_loss: 1.5554\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 1.2585 - val_loss: 1.2648\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 1.0642 - val_loss: 1.0880\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.9450 - val_loss: 0.9796\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.8710 - val_loss: 0.9110\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.8193 - val_loss: 0.8636\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.7817 - val_loss: 0.8299\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.7534 - val_loss: 0.8051\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.7317 - val_loss: 0.7867\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.7147 - val_loss: 0.7726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.7010 - val_loss: 0.7613\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.6896 - val_loss: 0.7520\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.6800 - val_loss: 0.7441\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 1s 89us/sample - loss: 0.6715 - val_loss: 0.7370\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.6638 - val_loss: 0.7306\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 1s 101us/sample - loss: 0.6569 - val_loss: 0.7245\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.6505 - val_loss: 0.7187\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 65us/sample - loss: 0.6444 - val_loss: 0.7130\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 1s 92us/sample - loss: 0.6387 - val_loss: 0.7076\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.6332 - val_loss: 0.7024\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.6280 - val_loss: 0.6971\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.6229 - val_loss: 0.6921\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.6182 - val_loss: 0.6870\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.6135 - val_loss: 0.6821\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.6089 - val_loss: 0.6771\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.6043 - val_loss: 0.6725\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.6001 - val_loss: 0.6676\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.5959 - val_loss: 0.6630\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.5916 - val_loss: 0.6584\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.5877 - val_loss: 0.6538\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.5838 - val_loss: 0.6493\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.5798 - val_loss: 0.6450\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.5761 - val_loss: 0.6407\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.5723 - val_loss: 0.6364\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.5686 - val_loss: 0.6324\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.5651 - val_loss: 0.6280\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.5615 - val_loss: 0.6238\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.5580 - val_loss: 0.6197\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.5546 - val_loss: 0.6157\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.5513 - val_loss: 0.6117\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.5480 - val_loss: 0.6077\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.5448 - val_loss: 0.6040\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.5415 - val_loss: 0.6002\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.5384 - val_loss: 0.5964\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5353 - val_loss: 0.5928\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.5322 - val_loss: 0.5891\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.5293 - val_loss: 0.5855\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.5263 - val_loss: 0.5820\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.5233 - val_loss: 0.5788\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 1s 76us/sample - loss: 0.5206 - val_loss: 0.5752\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.5177 - val_loss: 0.5719\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.5150 - val_loss: 0.5686\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.5122 - val_loss: 0.5654\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.5096 - val_loss: 0.5621\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.5070 - val_loss: 0.5589\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.5044 - val_loss: 0.5558\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.5019 - val_loss: 0.5527\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.4994 - val_loss: 0.5497\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.4970 - val_loss: 0.5467\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.4946 - val_loss: 0.5438\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4923 - val_loss: 0.5410\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.4899 - val_loss: 0.5381\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.4877 - val_loss: 0.5353\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.4854 - val_loss: 0.5326\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.4833 - val_loss: 0.5301\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.4812 - val_loss: 0.5276\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.4791 - val_loss: 0.5250\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.4771 - val_loss: 0.5225\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4751 - val_loss: 0.5201\n",
      "Epoch 72/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4732 - val_loss: 0.5177\n",
      "Epoch 73/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4714 - val_loss: 0.5153\n",
      "Epoch 74/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4694 - val_loss: 0.5131\n",
      "Epoch 75/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4677 - val_loss: 0.5108\n",
      "Epoch 76/100\n",
      "7740/7740 [==============================] - 1s 78us/sample - loss: 0.4658 - val_loss: 0.5086\n",
      "Epoch 77/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4641 - val_loss: 0.5064\n",
      "Epoch 78/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4624 - val_loss: 0.5044\n",
      "Epoch 79/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4607 - val_loss: 0.5024\n",
      "Epoch 80/100\n",
      "7740/7740 [==============================] - 1s 81us/sample - loss: 0.4591 - val_loss: 0.5004\n",
      "Epoch 81/100\n",
      "7740/7740 [==============================] - 1s 80us/sample - loss: 0.4575 - val_loss: 0.4983\n",
      "Epoch 82/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.4560 - val_loss: 0.4964\n",
      "Epoch 83/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.4544 - val_loss: 0.4945\n",
      "3870/3870 [==============================] - 0s 21us/sample - loss: 0.4984\n",
      "7740/7740 [==============================] - 0s 21us/sample - loss: 0.4532\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 150us/sample - loss: 1.7716 - val_loss: 0.8059\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.7149 - val_loss: 0.7172\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 1s 106us/sample - loss: 0.6549 - val_loss: 0.6690\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.6162 - val_loss: 0.6316\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.5834 - val_loss: 0.5982\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 1s 76us/sample - loss: 0.5565 - val_loss: 0.5787\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5345 - val_loss: 0.5449\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.5128 - val_loss: 0.5241\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 1s 87us/sample - loss: 0.4950 - val_loss: 0.5113\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 1s 109us/sample - loss: 0.4795 - val_loss: 0.4936\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.4643 - val_loss: 0.4737\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 1s 97us/sample - loss: 0.4516 - val_loss: 0.4637\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.4399 - val_loss: 0.4492\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.4298 - val_loss: 0.4390\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 1s 87us/sample - loss: 0.4197 - val_loss: 0.4292\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4129 - val_loss: 0.4210\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.4050 - val_loss: 0.4148\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 1s 79us/sample - loss: 0.3990 - val_loss: 0.4141\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 1s 87us/sample - loss: 0.3932 - val_loss: 0.4034\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 1s 81us/sample - loss: 0.3881 - val_loss: 0.4020\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 1s 83us/sample - loss: 0.3834 - val_loss: 0.3935\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 1s 85us/sample - loss: 0.3792 - val_loss: 0.3886\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3747 - val_loss: 0.3823\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3711 - val_loss: 0.3862\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3681 - val_loss: 0.3776\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.3649 - val_loss: 0.3739\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.3617 - val_loss: 0.3749\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 1s 79us/sample - loss: 0.3585 - val_loss: 0.3704\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 1s 115us/sample - loss: 0.3564 - val_loss: 0.3674\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 1s 132us/sample - loss: 0.3549 - val_loss: 0.3639\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 1s 117us/sample - loss: 0.3512 - val_loss: 0.3615\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 1s 84us/sample - loss: 0.3496 - val_loss: 0.3608\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3472 - val_loss: 0.3611\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 1s 79us/sample - loss: 0.3456 - val_loss: 0.3569\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 1s 129us/sample - loss: 0.3437 - val_loss: 0.3543\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.3415 - val_loss: 0.3551\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.3402 - val_loss: 0.3525\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.3383 - val_loss: 0.3510\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3367 - val_loss: 0.3500\n",
      "3870/3870 [==============================] - 0s 25us/sample - loss: 0.3275\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3339\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 87us/sample - loss: 1.7737 - val_loss: 0.8303\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 1s 75us/sample - loss: 0.6719 - val_loss: 0.6634\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 1s 93us/sample - loss: 0.5860 - val_loss: 0.6071\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 1s 95us/sample - loss: 0.5422 - val_loss: 0.5655\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 1s 82us/sample - loss: 0.5091 - val_loss: 0.5334\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 1s 87us/sample - loss: 0.4814 - val_loss: 0.5062\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 1s 98us/sample - loss: 0.4597 - val_loss: 0.4860\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 1s 92us/sample - loss: 0.4434 - val_loss: 0.4672\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 1s 77us/sample - loss: 0.4298 - val_loss: 0.4539\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 1s 79us/sample - loss: 0.4198 - val_loss: 0.4408\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 1s 147us/sample - loss: 0.4109 - val_loss: 0.4348\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 1s 78us/sample - loss: 0.4029 - val_loss: 0.4254\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.3975 - val_loss: 0.4174\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3923 - val_loss: 0.4121\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 1s 75us/sample - loss: 0.3866 - val_loss: 0.4052\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.3825 - val_loss: 0.3994\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3790 - val_loss: 0.3971\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3754 - val_loss: 0.3927\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.3718 - val_loss: 0.3896\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3687 - val_loss: 0.3859\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3659 - val_loss: 0.3841\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.3624 - val_loss: 0.3807\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3603 - val_loss: 0.3774\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3578 - val_loss: 0.3732\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3543 - val_loss: 0.3720\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3526 - val_loss: 0.3701\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3509 - val_loss: 0.3664\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3485 - val_loss: 0.3665\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3458 - val_loss: 0.3638\n",
      "3870/3870 [==============================] - 0s 22us/sample - loss: 0.3431\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.3426\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 83us/sample - loss: 1.5834 - val_loss: 0.8437\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.6369 - val_loss: 0.6638\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.5791 - val_loss: 0.6214\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.5453 - val_loss: 0.5870\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.5168 - val_loss: 0.5589\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.4950 - val_loss: 0.5356\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4752 - val_loss: 0.5141\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.4578 - val_loss: 0.4971\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.4439 - val_loss: 0.4801\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.4311 - val_loss: 0.4664\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4207 - val_loss: 0.4558\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.4105 - val_loss: 0.4443\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4027 - val_loss: 0.4352\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3948 - val_loss: 0.4298\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.3878 - val_loss: 0.4216\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3825 - val_loss: 0.4139\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3774 - val_loss: 0.4090\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.3729 - val_loss: 0.4037\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3686 - val_loss: 0.3990\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3646 - val_loss: 0.4023\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3607 - val_loss: 0.3929\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3576 - val_loss: 0.3859\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3550 - val_loss: 0.3862\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3519 - val_loss: 0.3826\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3485 - val_loss: 0.3785\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3461 - val_loss: 0.3788\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3434 - val_loss: 0.3748\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3414 - val_loss: 0.3723\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3400 - val_loss: 0.3730\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3368 - val_loss: 0.3672\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3357 - val_loss: 0.3673\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3336 - val_loss: 0.3660\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3315 - val_loss: 0.3655\n",
      "3870/3870 [==============================] - 0s 22us/sample - loss: 0.3754\n",
      "7740/7740 [==============================] - 0s 21us/sample - loss: 0.3282\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 84us/sample - loss: 1.9607 - val_loss: 0.8607\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.6953 - val_loss: 0.6672\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.6050 - val_loss: 0.6130\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5649 - val_loss: 0.5763\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.5347 - val_loss: 0.5477\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5110 - val_loss: 0.5259\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.4929 - val_loss: 0.5080\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.4770 - val_loss: 0.4970\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.4638 - val_loss: 0.4830\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.4518 - val_loss: 0.4735\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.4422 - val_loss: 0.4606\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.4328 - val_loss: 0.4504\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.4244 - val_loss: 0.4418\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.4164 - val_loss: 0.4345\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.4101 - val_loss: 0.4272\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.4041 - val_loss: 0.4227\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3971 - val_loss: 0.4157\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.3923 - val_loss: 0.4083\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3870 - val_loss: 0.4069\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.3825 - val_loss: 0.3989\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 1s 78us/sample - loss: 0.3786 - val_loss: 0.3945\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.3741 - val_loss: 0.3955\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 1s 75us/sample - loss: 0.3709 - val_loss: 0.3884\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 1s 74us/sample - loss: 0.3681 - val_loss: 0.3878\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.3642 - val_loss: 0.3833\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3621 - val_loss: 0.3781\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.3594 - val_loss: 0.3764\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.3571 - val_loss: 0.3758\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.3543 - val_loss: 0.3750\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.3522 - val_loss: 0.3712\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.3496 - val_loss: 0.3675\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.3486 - val_loss: 0.3678\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.3457 - val_loss: 0.3672\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 1s 76us/sample - loss: 0.3437 - val_loss: 0.3653\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.3425 - val_loss: 0.3622\n",
      "3870/3870 [==============================] - 0s 22us/sample - loss: 0.3411\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.3391\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 86us/sample - loss: 1.8331 - val_loss: 1.0612\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.7193 - val_loss: 0.7132\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.6411 - val_loss: 0.6720\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.6052 - val_loss: 0.6366\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.5756 - val_loss: 0.6090\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.5502 - val_loss: 0.5820\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5269 - val_loss: 0.5581\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.5057 - val_loss: 0.5348\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.4868 - val_loss: 0.5165\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.4703 - val_loss: 0.4980\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.4551 - val_loss: 0.4856\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.4441 - val_loss: 0.4710\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.4332 - val_loss: 0.4599\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.4243 - val_loss: 0.4484\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.4155 - val_loss: 0.4403\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.4084 - val_loss: 0.4312\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.4021 - val_loss: 0.4247\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.3955 - val_loss: 0.4203\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 1s 80us/sample - loss: 0.3902 - val_loss: 0.4122\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.3861 - val_loss: 0.4067\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 1s 94us/sample - loss: 0.3812 - val_loss: 0.4033\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3777 - val_loss: 0.3986\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.3741 - val_loss: 0.3974\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 1s 98us/sample - loss: 0.3711 - val_loss: 0.3909\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.3677 - val_loss: 0.3879\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3647 - val_loss: 0.3890\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 1s 101us/sample - loss: 0.3623 - val_loss: 0.3822\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.3591 - val_loss: 0.3783\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3570 - val_loss: 0.3760\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 1s 115us/sample - loss: 0.3545 - val_loss: 0.3769\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 1s 116us/sample - loss: 0.3522 - val_loss: 0.3758\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 1s 105us/sample - loss: 0.3511 - val_loss: 0.3722\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3483 - val_loss: 0.3689\n",
      "3870/3870 [==============================] - 0s 23us/sample - loss: 0.3495\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.3462\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 83us/sample - loss: 1.9302 - val_loss: 0.8288\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.6753 - val_loss: 0.6826\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.6020 - val_loss: 0.6428\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.5662 - val_loss: 0.6084\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.5374 - val_loss: 0.5805\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.5111 - val_loss: 0.5549\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.4894 - val_loss: 0.5291\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.4694 - val_loss: 0.5111\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.4546 - val_loss: 0.4920\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.4390 - val_loss: 0.4768\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.4276 - val_loss: 0.4661\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.4178 - val_loss: 0.4571\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.4093 - val_loss: 0.4496\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.4016 - val_loss: 0.4410\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3955 - val_loss: 0.4311\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.3899 - val_loss: 0.4244\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.3847 - val_loss: 0.4210\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.3802 - val_loss: 0.4233\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3761 - val_loss: 0.4120\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3718 - val_loss: 0.4062\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3692 - val_loss: 0.4043\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.3643 - val_loss: 0.3993\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.3609 - val_loss: 0.4024\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3604 - val_loss: 0.3924\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3562 - val_loss: 0.3911\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3526 - val_loss: 0.3856\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3508 - val_loss: 0.3842\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3469 - val_loss: 0.3869\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3446 - val_loss: 0.3784\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3435 - val_loss: 0.3783\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3400 - val_loss: 0.3766\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3375 - val_loss: 0.3701\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3358 - val_loss: 0.3751\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3346 - val_loss: 0.3696\n",
      "3870/3870 [==============================] - 0s 22us/sample - loss: 0.3792\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.3309\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 74us/sample - loss: 4.2745 - val_loss: 3.2450\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 2.3468 - val_loss: 1.8942\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 1.5358 - val_loss: 1.4368\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 1.3041 - val_loss: 1.3148\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 1.2257 - val_loss: 1.2524\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 1.1740 - val_loss: 1.1983\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 1.1203 - val_loss: 1.1376\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 1.0591 - val_loss: 1.0686\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.9912 - val_loss: 0.9948\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.9222 - val_loss: 0.9224\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.8584 - val_loss: 0.8593\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.8050 - val_loss: 0.8049\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 1s 76us/sample - loss: 0.7642 - val_loss: 0.7670\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.7334 - val_loss: 0.7368\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.7097 - val_loss: 0.7130\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.6899 - val_loss: 0.6936\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.6736 - val_loss: 0.6776\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.6592 - val_loss: 0.6625\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.6457 - val_loss: 0.6503\n",
      "Epoch 20/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.6339 - val_loss: 0.6379\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 1s 74us/sample - loss: 0.6221 - val_loss: 0.6268\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.6116 - val_loss: 0.6163\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.6016 - val_loss: 0.6067\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.5919 - val_loss: 0.5969\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.5831 - val_loss: 0.5878\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5745 - val_loss: 0.5782\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.5663 - val_loss: 0.5699\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5582 - val_loss: 0.5619\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5503 - val_loss: 0.5531\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.5428 - val_loss: 0.5448\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5355 - val_loss: 0.5371\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.5282 - val_loss: 0.5297\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5212 - val_loss: 0.5216\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5145 - val_loss: 0.5140\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.5078 - val_loss: 0.5076\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5010 - val_loss: 0.5003\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4947 - val_loss: 0.4937\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4886 - val_loss: 0.4866\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 1s 117us/sample - loss: 0.4824 - val_loss: 0.4820\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 1s 137us/sample - loss: 0.4765 - val_loss: 0.4750\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4713 - val_loss: 0.4696\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.4658 - val_loss: 0.4649\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.4611 - val_loss: 0.4588\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.4568 - val_loss: 0.4549\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4526 - val_loss: 0.4518\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4483 - val_loss: 0.4468\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.4451 - val_loss: 0.4418\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.4415 - val_loss: 0.4379\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.4382 - val_loss: 0.4364\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4354 - val_loss: 0.4320\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.4327 - val_loss: 0.4294\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.4302 - val_loss: 0.4269\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.4277 - val_loss: 0.4237\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.4256 - val_loss: 0.4213\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4235 - val_loss: 0.4204\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.4217 - val_loss: 0.4182\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.4198 - val_loss: 0.4179\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4184 - val_loss: 0.4153\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.4170 - val_loss: 0.4140\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.4154 - val_loss: 0.4115\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4142 - val_loss: 0.4125\n",
      "3870/3870 [==============================] - 0s 20us/sample - loss: 0.3851\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4144\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 75us/sample - loss: 4.7120 - val_loss: 3.8421\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 2.9627 - val_loss: 2.5628\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 2.0444 - val_loss: 1.8858\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 1.5854 - val_loss: 1.5605\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 1.3861 - val_loss: 1.4240\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 1.3101 - val_loss: 1.3692\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 1.2822 - val_loss: 1.3464\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 1.2697 - val_loss: 1.3326\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 1.2609 - val_loss: 1.3211\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 1.2519 - val_loss: 1.3089\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 1.2420 - val_loss: 1.2957\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 1.2301 - val_loss: 1.2798\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 1.2154 - val_loss: 1.2606\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 1.1976 - val_loss: 1.2369\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 1.1758 - val_loss: 1.2088\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 1.1487 - val_loss: 1.1731\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 1.1155 - val_loss: 1.1306\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 1.0751 - val_loss: 1.0806\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 1.0271 - val_loss: 1.0231\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.9722 - val_loss: 0.9589\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.9168 - val_loss: 0.8999\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.8648 - val_loss: 0.8496\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.8214 - val_loss: 0.8128\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.7875 - val_loss: 0.7845\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.7616 - val_loss: 0.7648\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.7421 - val_loss: 0.7518\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.7275 - val_loss: 0.7406\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.7157 - val_loss: 0.7322\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.7059 - val_loss: 0.7247\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.6975 - val_loss: 0.7180\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.6896 - val_loss: 0.7118\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.6820 - val_loss: 0.7060\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.6751 - val_loss: 0.7006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.6689 - val_loss: 0.6955\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.6632 - val_loss: 0.6907\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.6579 - val_loss: 0.6856\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.6532 - val_loss: 0.6809\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.6485 - val_loss: 0.6764\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.6440 - val_loss: 0.6718\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.6394 - val_loss: 0.6672\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.6348 - val_loss: 0.6629\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.6304 - val_loss: 0.6582\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.6256 - val_loss: 0.6537\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.6210 - val_loss: 0.6494\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.6164 - val_loss: 0.6448\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.6120 - val_loss: 0.6403\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.6076 - val_loss: 0.6358\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.6031 - val_loss: 0.6312\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.5989 - val_loss: 0.6265\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.5944 - val_loss: 0.6221\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.5899 - val_loss: 0.6172\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.5854 - val_loss: 0.6125\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.5806 - val_loss: 0.6076\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5762 - val_loss: 0.6027\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.5716 - val_loss: 0.5980\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5669 - val_loss: 0.5934\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.5624 - val_loss: 0.5886\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.5579 - val_loss: 0.5838\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.5535 - val_loss: 0.5794\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.5486 - val_loss: 0.5747\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5445 - val_loss: 0.5697\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.5400 - val_loss: 0.5651\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5354 - val_loss: 0.5606\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5312 - val_loss: 0.5561\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5271 - val_loss: 0.5513\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5227 - val_loss: 0.5470\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.5186 - val_loss: 0.5425\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.5144 - val_loss: 0.5381\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.5102 - val_loss: 0.5340\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.5065 - val_loss: 0.5296\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.5026 - val_loss: 0.5259\n",
      "Epoch 72/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4990 - val_loss: 0.5218\n",
      "Epoch 73/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4953 - val_loss: 0.5183\n",
      "Epoch 74/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.4918 - val_loss: 0.5144\n",
      "Epoch 75/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.4884 - val_loss: 0.5108\n",
      "Epoch 76/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4851 - val_loss: 0.5076\n",
      "Epoch 77/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.4819 - val_loss: 0.5042\n",
      "Epoch 78/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.4787 - val_loss: 0.5014\n",
      "Epoch 79/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.4758 - val_loss: 0.4979\n",
      "Epoch 80/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4730 - val_loss: 0.4948\n",
      "Epoch 81/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4703 - val_loss: 0.4920\n",
      "Epoch 82/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4677 - val_loss: 0.4892\n",
      "Epoch 83/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.4655 - val_loss: 0.4866\n",
      "Epoch 84/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.4633 - val_loss: 0.4840\n",
      "Epoch 85/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.4610 - val_loss: 0.4824\n",
      "Epoch 86/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.4593 - val_loss: 0.4796\n",
      "Epoch 87/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.4574 - val_loss: 0.4772\n",
      "Epoch 88/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.4556 - val_loss: 0.4753\n",
      "Epoch 89/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.4539 - val_loss: 0.4731\n",
      "Epoch 90/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.4524 - val_loss: 0.4711\n",
      "Epoch 91/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.4510 - val_loss: 0.4694\n",
      "Epoch 92/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.4497 - val_loss: 0.4679\n",
      "Epoch 93/100\n",
      "7740/7740 [==============================] - 1s 81us/sample - loss: 0.4484 - val_loss: 0.4667\n",
      "3870/3870 [==============================] - 0s 20us/sample - loss: 0.4508\n",
      "7740/7740 [==============================] - 0s 20us/sample - loss: 0.4474\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 139us/sample - loss: 3.8818 - val_loss: 2.2452\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 1.6084 - val_loss: 1.4383\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 1.2853 - val_loss: 1.2814\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 1.1804 - val_loss: 1.1763\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 1.1002 - val_loss: 1.1095\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 1.0332 - val_loss: 1.0374\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.9684 - val_loss: 0.9748\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.9106 - val_loss: 0.9229\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.8588 - val_loss: 0.8791\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.8164 - val_loss: 0.8456\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.7832 - val_loss: 0.8195\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.7582 - val_loss: 0.8021\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.7387 - val_loss: 0.7867\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.7236 - val_loss: 0.7744\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.7109 - val_loss: 0.7655\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.7003 - val_loss: 0.7524\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.6902 - val_loss: 0.7441\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.6814 - val_loss: 0.7334\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.6727 - val_loss: 0.7256\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.6649 - val_loss: 0.7150\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.6568 - val_loss: 0.7066\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.6486 - val_loss: 0.6983\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.6412 - val_loss: 0.6906\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.6330 - val_loss: 0.6821\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.6248 - val_loss: 0.6737\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.6162 - val_loss: 0.6649\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.6086 - val_loss: 0.6570\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.5999 - val_loss: 0.6480\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.5909 - val_loss: 0.6390\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5817 - val_loss: 0.6300\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.5720 - val_loss: 0.6207\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5629 - val_loss: 0.6116\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5532 - val_loss: 0.6013\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.5433 - val_loss: 0.5922\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5337 - val_loss: 0.5829\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.5244 - val_loss: 0.5726\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5148 - val_loss: 0.5636\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5059 - val_loss: 0.5546\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4967 - val_loss: 0.5471\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4889 - val_loss: 0.5392\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.4805 - val_loss: 0.5306\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4735 - val_loss: 0.5231\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4665 - val_loss: 0.5159\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4599 - val_loss: 0.5091\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4537 - val_loss: 0.5029\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4480 - val_loss: 0.4967\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4427 - val_loss: 0.4914\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4376 - val_loss: 0.4868\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4330 - val_loss: 0.4818\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4288 - val_loss: 0.4777\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4249 - val_loss: 0.4746\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.4213 - val_loss: 0.4704\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4182 - val_loss: 0.4664\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4151 - val_loss: 0.4628\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4121 - val_loss: 0.4594\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4093 - val_loss: 0.4562\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.4073 - val_loss: 0.4527\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4048 - val_loss: 0.4503\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4026 - val_loss: 0.4472\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4008 - val_loss: 0.4446\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3988 - val_loss: 0.4424\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3969 - val_loss: 0.4396\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3952 - val_loss: 0.4374\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3933 - val_loss: 0.4362\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3917 - val_loss: 0.4347\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3904 - val_loss: 0.4325\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3889 - val_loss: 0.4312\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3877 - val_loss: 0.4287\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3865 - val_loss: 0.4271\n",
      "3870/3870 [==============================] - 0s 19us/sample - loss: 0.4279\n",
      "7740/7740 [==============================] - 0s 20us/sample - loss: 0.3850\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 78us/sample - loss: 1.2115 - val_loss: 0.7461\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.6644 - val_loss: 0.6541\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.5869 - val_loss: 0.5879\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.5307 - val_loss: 0.5384\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.4911 - val_loss: 0.5044\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.4633 - val_loss: 0.4810\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.4443 - val_loss: 0.4602\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.4292 - val_loss: 0.4480\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.4182 - val_loss: 0.4365\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.4068 - val_loss: 0.4280\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3990 - val_loss: 0.4207\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3926 - val_loss: 0.4103\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3859 - val_loss: 0.4066\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3801 - val_loss: 0.3979\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3741 - val_loss: 0.3938\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3685 - val_loss: 0.3909\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3646 - val_loss: 0.3855\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3599 - val_loss: 0.3809\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3559 - val_loss: 0.3845\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3527 - val_loss: 0.3745\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3489 - val_loss: 0.3763\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3456 - val_loss: 0.3695\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3434 - val_loss: 0.3681\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3410 - val_loss: 0.3693\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3378 - val_loss: 0.3604\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3352 - val_loss: 0.3584\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3319 - val_loss: 0.3563\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3299 - val_loss: 0.3533\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3279 - val_loss: 0.3520\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3243 - val_loss: 0.3550\n",
      "3870/3870 [==============================] - 0s 22us/sample - loss: 0.3292\n",
      "7740/7740 [==============================] - 0s 20us/sample - loss: 0.3275\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 80us/sample - loss: 1.2924 - val_loss: 0.6277\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.5399 - val_loss: 0.5563\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.4971 - val_loss: 0.5210\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.4678 - val_loss: 0.4885\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.4466 - val_loss: 0.4670\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.4304 - val_loss: 0.4498\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.4175 - val_loss: 0.4414\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.4079 - val_loss: 0.4272\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3974 - val_loss: 0.4144\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3886 - val_loss: 0.4075\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3827 - val_loss: 0.4009\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3777 - val_loss: 0.3953\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3729 - val_loss: 0.3988\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3689 - val_loss: 0.3880\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3648 - val_loss: 0.3839\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3621 - val_loss: 0.3843\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3581 - val_loss: 0.3800\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3551 - val_loss: 0.3791\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3540 - val_loss: 0.3746\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3498 - val_loss: 0.3697\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3476 - val_loss: 0.3680\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3461 - val_loss: 0.3672\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3442 - val_loss: 0.3678\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3417 - val_loss: 0.3592\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3394 - val_loss: 0.3669\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3377 - val_loss: 0.3593\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3354 - val_loss: 0.3563\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3328 - val_loss: 0.3538\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3319 - val_loss: 0.3510\n",
      "3870/3870 [==============================] - 0s 20us/sample - loss: 0.3265\n",
      "7740/7740 [==============================] - 0s 19us/sample - loss: 0.3245\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 79us/sample - loss: 1.1731 - val_loss: 0.6997\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.5831 - val_loss: 0.6082\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.5214 - val_loss: 0.5554\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.4815 - val_loss: 0.5130\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.4535 - val_loss: 0.4864\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.4327 - val_loss: 0.4612\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.4153 - val_loss: 0.4502\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.4032 - val_loss: 0.4337\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3938 - val_loss: 0.4255\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3842 - val_loss: 0.4163\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3778 - val_loss: 0.4069\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3724 - val_loss: 0.4000\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3662 - val_loss: 0.3956\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3623 - val_loss: 0.3929\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3558 - val_loss: 0.3962\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3525 - val_loss: 0.3937\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3488 - val_loss: 0.3805\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3460 - val_loss: 0.3767\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3429 - val_loss: 0.3774\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3386 - val_loss: 0.3743\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3372 - val_loss: 0.3679\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3334 - val_loss: 0.3728\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3306 - val_loss: 0.3740\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3273 - val_loss: 0.3636\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3252 - val_loss: 0.3647\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3235 - val_loss: 0.3585\n",
      "3870/3870 [==============================] - 0s 20us/sample - loss: 0.3685\n",
      "7740/7740 [==============================] - 0s 20us/sample - loss: 0.3190\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 1.8117 - val_loss: 0.8631\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.7399 - val_loss: 0.7045\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.6629 - val_loss: 0.6516\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.6212 - val_loss: 0.6123\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.5844 - val_loss: 0.5791\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5544 - val_loss: 0.5546\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5330 - val_loss: 0.5349\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.5157 - val_loss: 0.5205\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.5013 - val_loss: 0.5060\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4896 - val_loss: 0.4951\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4818 - val_loss: 0.4886\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4752 - val_loss: 0.4821\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4713 - val_loss: 0.4762\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4681 - val_loss: 0.4744\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4629 - val_loss: 0.4738\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4603 - val_loss: 0.4656\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4566 - val_loss: 0.4674\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4540 - val_loss: 0.4599\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4516 - val_loss: 0.4578\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4474 - val_loss: 0.4548\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4492 - val_loss: 0.4585\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4473 - val_loss: 0.4515\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4477 - val_loss: 0.4591\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4477 - val_loss: 0.4494\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4455 - val_loss: 0.4498\n",
      "3870/3870 [==============================] - 0s 20us/sample - loss: 0.4169\n",
      "7740/7740 [==============================] - 0s 18us/sample - loss: 0.4435\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 1.9376 - val_loss: 1.4473\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 1.2149 - val_loss: 1.1853\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 1.0503 - val_loss: 1.0600\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.9666 - val_loss: 0.9860\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.9032 - val_loss: 0.9245\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.8518 - val_loss: 0.8716\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.8021 - val_loss: 0.8183\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.7473 - val_loss: 0.7630\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.6955 - val_loss: 0.7148\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.6456 - val_loss: 0.6602\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.5979 - val_loss: 0.6137\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5564 - val_loss: 0.5730\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.5234 - val_loss: 0.5476\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.5101 - val_loss: 0.5507\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.5051 - val_loss: 0.5225\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.4900 - val_loss: 0.5073\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4770 - val_loss: 0.4953\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4847 - val_loss: 0.4942\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4860 - val_loss: 0.5154\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4849 - val_loss: 0.5039\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4739 - val_loss: 0.4885\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4716 - val_loss: 0.4986\n",
      "3870/3870 [==============================] - 0s 21us/sample - loss: 0.4722\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4712\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 75us/sample - loss: 1.9414 - val_loss: 1.2386\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.9238 - val_loss: 0.8366\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.6897 - val_loss: 0.6818\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.5955 - val_loss: 0.6259\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.5582 - val_loss: 0.5986\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5351 - val_loss: 0.5759\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5155 - val_loss: 0.5583\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5000 - val_loss: 0.5443\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4875 - val_loss: 0.5250\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.4767 - val_loss: 0.5106\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4671 - val_loss: 0.4978\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.4587 - val_loss: 0.4882\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4518 - val_loss: 0.4810\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4471 - val_loss: 0.4765\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4432 - val_loss: 0.4719\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4399 - val_loss: 0.4718\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4373 - val_loss: 0.4667\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4354 - val_loss: 0.4650\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4332 - val_loss: 0.4618\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4313 - val_loss: 0.4620\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4298 - val_loss: 0.4575\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4278 - val_loss: 0.4592\n",
      "3870/3870 [==============================] - 0s 26us/sample - loss: 0.4668\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.4264\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 11.4355 - val_loss: 10.0450\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 8.2605 - val_loss: 7.5196\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 6.3110 - val_loss: 5.8819\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 5.0082 - val_loss: 4.7475\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 4.0895 - val_loss: 3.9268\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 3.4167 - val_loss: 3.3152\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 2.9104 - val_loss: 2.8475\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 2.5217 - val_loss: 2.4856\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 2.2188 - val_loss: 2.2012\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 48us/sample - loss: 1.9795 - val_loss: 1.9749\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 1.7889 - val_loss: 1.7938\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 1.6353 - val_loss: 1.6466\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 1.5095 - val_loss: 1.5259\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 1.4055 - val_loss: 1.4261\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 1.3186 - val_loss: 1.3429\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 1.2454 - val_loss: 1.2725\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 1.1830 - val_loss: 1.2129\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 1.1297 - val_loss: 1.1616\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 1.0837 - val_loss: 1.1174\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 1.0437 - val_loss: 1.0789\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 1.0085 - val_loss: 1.0451\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.9776 - val_loss: 1.0153\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.9502 - val_loss: 0.9888\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.9259 - val_loss: 0.9653\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.9043 - val_loss: 0.9443\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.8848 - val_loss: 0.9253\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.8672 - val_loss: 0.9082\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.8513 - val_loss: 0.8928\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.8369 - val_loss: 0.8788\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.8239 - val_loss: 0.8661\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.8120 - val_loss: 0.8544\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.8011 - val_loss: 0.8437\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.7911 - val_loss: 0.8338\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.7819 - val_loss: 0.8247\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.7734 - val_loss: 0.8161\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.7655 - val_loss: 0.8082\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.7582 - val_loss: 0.8008\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.7515 - val_loss: 0.7938\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.7452 - val_loss: 0.7872\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.7393 - val_loss: 0.7810\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.7337 - val_loss: 0.7752\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.7285 - val_loss: 0.7698\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.7235 - val_loss: 0.7646\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.7189 - val_loss: 0.7596\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.7144 - val_loss: 0.7550\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.7102 - val_loss: 0.7505\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.7063 - val_loss: 0.7462\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.7024 - val_loss: 0.7421\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.6987 - val_loss: 0.7381\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.6952 - val_loss: 0.7344\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.6918 - val_loss: 0.7307\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.6885 - val_loss: 0.7271\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.6854 - val_loss: 0.7236\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.6822 - val_loss: 0.7202\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.6792 - val_loss: 0.7169\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.6763 - val_loss: 0.7137\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.6734 - val_loss: 0.7107\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.6706 - val_loss: 0.7077\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.6680 - val_loss: 0.7048\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.6654 - val_loss: 0.7021\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.6629 - val_loss: 0.6993\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.6604 - val_loss: 0.6967\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.6580 - val_loss: 0.6942\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.6557 - val_loss: 0.6917\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.6534 - val_loss: 0.6893\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.6512 - val_loss: 0.6870\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.6491 - val_loss: 0.6848\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.6470 - val_loss: 0.6826\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.6450 - val_loss: 0.6804\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.6430 - val_loss: 0.6783\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.6411 - val_loss: 0.6763\n",
      "Epoch 72/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.6393 - val_loss: 0.6743\n",
      "Epoch 73/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.6374 - val_loss: 0.6724\n",
      "Epoch 74/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.6357 - val_loss: 0.6706\n",
      "Epoch 75/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.6339 - val_loss: 0.6687\n",
      "3870/3870 [==============================] - 0s 18us/sample - loss: 0.5871\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.6329\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 73us/sample - loss: 4.3808 - val_loss: 3.6320\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 3.3802 - val_loss: 2.8226\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 2.6976 - val_loss: 2.2734\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 2.2215 - val_loss: 1.8975\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 1.8809 - val_loss: 1.6330\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 1.6350 - val_loss: 1.4467\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 1.4531 - val_loss: 1.3122\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 1.3164 - val_loss: 1.2131\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 1.2128 - val_loss: 1.1393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 1.1326 - val_loss: 1.0834\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 1.0724 - val_loss: 1.0393\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 1.0236 - val_loss: 1.0042\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.9836 - val_loss: 0.9757\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.9503 - val_loss: 0.9520\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.9223 - val_loss: 0.9322\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.8985 - val_loss: 0.9153\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.8780 - val_loss: 0.9008\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.8601 - val_loss: 0.8881\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.8445 - val_loss: 0.8768\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.8306 - val_loss: 0.8665\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.8180 - val_loss: 0.8573\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.8066 - val_loss: 0.8489\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.7963 - val_loss: 0.8410\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.7866 - val_loss: 0.8336\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.7777 - val_loss: 0.8267\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.7694 - val_loss: 0.8202\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.7616 - val_loss: 0.8140\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.7542 - val_loss: 0.8081\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.7472 - val_loss: 0.8024\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.7405 - val_loss: 0.7969\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.7341 - val_loss: 0.7915\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.7279 - val_loss: 0.7863\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.7219 - val_loss: 0.7812\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.7162 - val_loss: 0.7762\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.7107 - val_loss: 0.7713\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.7054 - val_loss: 0.7666\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.7003 - val_loss: 0.7620\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.6953 - val_loss: 0.7574\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.6904 - val_loss: 0.7530\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.6858 - val_loss: 0.7487\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.6812 - val_loss: 0.7445\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.6768 - val_loss: 0.7403\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.6725 - val_loss: 0.7363\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.6683 - val_loss: 0.7323\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.6642 - val_loss: 0.7285\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.6603 - val_loss: 0.7246\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.6564 - val_loss: 0.7209\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.6527 - val_loss: 0.7173\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.6490 - val_loss: 0.7137\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.6455 - val_loss: 0.7102\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.6420 - val_loss: 0.7068\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.6387 - val_loss: 0.7034\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.6354 - val_loss: 0.7000\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.6321 - val_loss: 0.6968\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.6290 - val_loss: 0.6936\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.6259 - val_loss: 0.6905\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.6229 - val_loss: 0.6874\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.6199 - val_loss: 0.6843\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.6171 - val_loss: 0.6814\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.6142 - val_loss: 0.6785\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.6115 - val_loss: 0.6756\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.6088 - val_loss: 0.6729\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.6062 - val_loss: 0.6701\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.6036 - val_loss: 0.6674\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.6010 - val_loss: 0.6648\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5986 - val_loss: 0.6620\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5961 - val_loss: 0.6593\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5937 - val_loss: 0.6566\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5914 - val_loss: 0.6540\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5891 - val_loss: 0.6515\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5869 - val_loss: 0.6490\n",
      "Epoch 72/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5847 - val_loss: 0.6465\n",
      "Epoch 73/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.5826 - val_loss: 0.6440\n",
      "Epoch 74/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5804 - val_loss: 0.6416\n",
      "Epoch 75/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5784 - val_loss: 0.6393\n",
      "Epoch 76/100\n",
      "7740/7740 [==============================] - 1s 77us/sample - loss: 0.5764 - val_loss: 0.6370\n",
      "Epoch 77/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.5744 - val_loss: 0.6347\n",
      "Epoch 78/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5725 - val_loss: 0.6325\n",
      "Epoch 79/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.5705 - val_loss: 0.6303\n",
      "Epoch 80/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.5687 - val_loss: 0.6281\n",
      "Epoch 81/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.5669 - val_loss: 0.6260\n",
      "Epoch 82/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5651 - val_loss: 0.6239\n",
      "Epoch 83/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5633 - val_loss: 0.6218\n",
      "Epoch 84/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.5616 - val_loss: 0.6198\n",
      "Epoch 85/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.5599 - val_loss: 0.6178\n",
      "Epoch 86/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 1s 154us/sample - loss: 0.5583 - val_loss: 0.6158\n",
      "Epoch 87/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.5566 - val_loss: 0.6138\n",
      "Epoch 88/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.5550 - val_loss: 0.6119\n",
      "Epoch 89/100\n",
      "7740/7740 [==============================] - 1s 83us/sample - loss: 0.5534 - val_loss: 0.6101\n",
      "Epoch 90/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.5518 - val_loss: 0.6082\n",
      "Epoch 91/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5503 - val_loss: 0.6064\n",
      "Epoch 92/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5488 - val_loss: 0.6045\n",
      "3870/3870 [==============================] - 0s 19us/sample - loss: 0.5582\n",
      "7740/7740 [==============================] - 0s 20us/sample - loss: 0.5479\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 89us/sample - loss: 4.8810 - val_loss: 4.2959\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 3.5978 - val_loss: 3.2401\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 2.7578 - val_loss: 2.5341\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 2.1927 - val_loss: 2.0480\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 1.8039 - val_loss: 1.7105\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 1.5301 - val_loss: 1.4705\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 1.3340 - val_loss: 1.2982\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 1.1904 - val_loss: 1.1712\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 1.0828 - val_loss: 1.0760\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 1.0010 - val_loss: 1.0034\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.9375 - val_loss: 0.9473\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.8869 - val_loss: 0.9025\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.8460 - val_loss: 0.8668\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 1s 92us/sample - loss: 0.8125 - val_loss: 0.8381\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.7847 - val_loss: 0.8146\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.7614 - val_loss: 0.7949\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.7418 - val_loss: 0.7785\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.7252 - val_loss: 0.7645\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.7109 - val_loss: 0.7526\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.6987 - val_loss: 0.7424\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 1s 79us/sample - loss: 0.6880 - val_loss: 0.7335\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.6786 - val_loss: 0.7257\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.6702 - val_loss: 0.7188\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.6628 - val_loss: 0.7126\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.6561 - val_loss: 0.7071\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.6499 - val_loss: 0.7020\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.6444 - val_loss: 0.6973\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.6392 - val_loss: 0.6930\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.6345 - val_loss: 0.6889\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.6300 - val_loss: 0.6851\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.6259 - val_loss: 0.6815\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.6219 - val_loss: 0.6780\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.6182 - val_loss: 0.6747\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.6147 - val_loss: 0.6715\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.6113 - val_loss: 0.6684\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.6080 - val_loss: 0.6654\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.6049 - val_loss: 0.6624\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.6018 - val_loss: 0.6595\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5989 - val_loss: 0.6567\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5960 - val_loss: 0.6540\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5932 - val_loss: 0.6513\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5905 - val_loss: 0.6486\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5878 - val_loss: 0.6460\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5852 - val_loss: 0.6435\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5827 - val_loss: 0.6409\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5802 - val_loss: 0.6384\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5778 - val_loss: 0.6360\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.5754 - val_loss: 0.6336\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.5731 - val_loss: 0.6312\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 1s 89us/sample - loss: 0.5708 - val_loss: 0.6288\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.5685 - val_loss: 0.6265\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5663 - val_loss: 0.6243\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.5641 - val_loss: 0.6220\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.5620 - val_loss: 0.6198\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.5599 - val_loss: 0.6176\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5579 - val_loss: 0.6155\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.5558 - val_loss: 0.6134\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5539 - val_loss: 0.6113\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5519 - val_loss: 0.6093\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5500 - val_loss: 0.6073\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.5482 - val_loss: 0.6053\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5463 - val_loss: 0.6033\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5445 - val_loss: 0.6014\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5427 - val_loss: 0.5995\n",
      "3870/3870 [==============================] - 0s 18us/sample - loss: 0.5945\n",
      "7740/7740 [==============================] - 0s 17us/sample - loss: 0.5417\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 83us/sample - loss: 2.3392 - val_loss: 1.0875\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.8724 - val_loss: 0.7562\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.6654 - val_loss: 0.6494\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.5986 - val_loss: 0.6088\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.5654 - val_loss: 0.5805\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.5404 - val_loss: 0.5559\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.5197 - val_loss: 0.5376\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.5023 - val_loss: 0.5173\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.4881 - val_loss: 0.5037\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4757 - val_loss: 0.4924\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.4647 - val_loss: 0.4841\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.4555 - val_loss: 0.4741\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.4476 - val_loss: 0.4653\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.4402 - val_loss: 0.4560\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4332 - val_loss: 0.4493\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.4269 - val_loss: 0.4433\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.4215 - val_loss: 0.4376\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4150 - val_loss: 0.4349\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.4097 - val_loss: 0.4253\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4039 - val_loss: 0.4207\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3992 - val_loss: 0.4203\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3951 - val_loss: 0.4100\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3906 - val_loss: 0.4086\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3864 - val_loss: 0.4021\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3821 - val_loss: 0.4041\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.3787 - val_loss: 0.3961\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3748 - val_loss: 0.3909\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3712 - val_loss: 0.3877\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3684 - val_loss: 0.3856\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3657 - val_loss: 0.3817\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3625 - val_loss: 0.3798\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3602 - val_loss: 0.3778\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3574 - val_loss: 0.3754\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3556 - val_loss: 0.3720\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.3530 - val_loss: 0.3705\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3505 - val_loss: 0.3672\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3488 - val_loss: 0.3648\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3461 - val_loss: 0.3647\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3451 - val_loss: 0.3618\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3425 - val_loss: 0.3599\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3404 - val_loss: 0.3597\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3393 - val_loss: 0.3566\n",
      "3870/3870 [==============================] - 0s 23us/sample - loss: 0.3341\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.3356\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 86us/sample - loss: 1.8960 - val_loss: 1.0188\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.8308 - val_loss: 0.7232\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.6344 - val_loss: 0.6659\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.5966 - val_loss: 0.6357\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.5699 - val_loss: 0.6077\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.5474 - val_loss: 0.5833\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.5276 - val_loss: 0.5632\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.5099 - val_loss: 0.5447\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.4942 - val_loss: 0.5284\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.4794 - val_loss: 0.5102\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.4658 - val_loss: 0.4942\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.4529 - val_loss: 0.4812\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.4413 - val_loss: 0.4701\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.4319 - val_loss: 0.4590\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.4233 - val_loss: 0.4492\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.4156 - val_loss: 0.4418\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 1s 78us/sample - loss: 0.4097 - val_loss: 0.4341\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4034 - val_loss: 0.4280\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 1s 93us/sample - loss: 0.3982 - val_loss: 0.4224\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 1s 76us/sample - loss: 0.3942 - val_loss: 0.4168\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.3898 - val_loss: 0.4130\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.3867 - val_loss: 0.4081\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3829 - val_loss: 0.4054\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.3798 - val_loss: 0.4010\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3773 - val_loss: 0.3966\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.3744 - val_loss: 0.3943\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.3717 - val_loss: 0.3953\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.3699 - val_loss: 0.3906\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3674 - val_loss: 0.3902\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.3657 - val_loss: 0.3853\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3641 - val_loss: 0.3841\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3626 - val_loss: 0.3825\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3609 - val_loss: 0.3821\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3596 - val_loss: 0.3777\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3580 - val_loss: 0.3771\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3566 - val_loss: 0.3750\n",
      "3870/3870 [==============================] - 0s 23us/sample - loss: 0.3535\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.3540\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 82us/sample - loss: 2.1128 - val_loss: 1.0631\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.8113 - val_loss: 0.7481\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.6531 - val_loss: 0.6862\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.6120 - val_loss: 0.6534\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.5839 - val_loss: 0.6256\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.5593 - val_loss: 0.5995\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.5373 - val_loss: 0.5804\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.5178 - val_loss: 0.5588\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.5002 - val_loss: 0.5395\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.4844 - val_loss: 0.5222\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.4701 - val_loss: 0.5083\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.4573 - val_loss: 0.4940\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.4467 - val_loss: 0.4836\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4365 - val_loss: 0.4717\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.4273 - val_loss: 0.4620\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.4189 - val_loss: 0.4539\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.4109 - val_loss: 0.4441\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4037 - val_loss: 0.4386\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3978 - val_loss: 0.4303\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3911 - val_loss: 0.4239\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3860 - val_loss: 0.4162\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3800 - val_loss: 0.4126\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3755 - val_loss: 0.4072\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3713 - val_loss: 0.4018\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3662 - val_loss: 0.3983\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3627 - val_loss: 0.3923\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3588 - val_loss: 0.3878\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3554 - val_loss: 0.3867\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3523 - val_loss: 0.3843\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3493 - val_loss: 0.3783\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3467 - val_loss: 0.3801\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3438 - val_loss: 0.3739\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3411 - val_loss: 0.3740\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3392 - val_loss: 0.3703\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3362 - val_loss: 0.3693\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3351 - val_loss: 0.3679\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3322 - val_loss: 0.3707\n",
      "3870/3870 [==============================] - 0s 22us/sample - loss: 0.3799\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.3357\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 75us/sample - loss: 4.4552 - val_loss: 3.8352\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 3.1052 - val_loss: 2.7338\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 2.2799 - val_loss: 2.0798\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 1.8009 - val_loss: 1.7042\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 1.5117 - val_loss: 1.4567\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 1.3163 - val_loss: 1.2851\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 1.1751 - val_loss: 1.1556\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 1.0674 - val_loss: 1.0563\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.9831 - val_loss: 0.9788\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.9164 - val_loss: 0.9180\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.8632 - val_loss: 0.8705\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.8213 - val_loss: 0.8333\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.7883 - val_loss: 0.8042\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.7620 - val_loss: 0.7815\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.7412 - val_loss: 0.7637\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.7248 - val_loss: 0.7497\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.7115 - val_loss: 0.7383\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.7006 - val_loss: 0.7288\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.6914 - val_loss: 0.7208\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.6835 - val_loss: 0.7138\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.6765 - val_loss: 0.7076\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.6702 - val_loss: 0.7019\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.6645 - val_loss: 0.6966\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.6592 - val_loss: 0.6917\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.6544 - val_loss: 0.6870\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.6498 - val_loss: 0.6826\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.6454 - val_loss: 0.6783\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.6413 - val_loss: 0.6743\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.6373 - val_loss: 0.6704\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.6334 - val_loss: 0.6667\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.6298 - val_loss: 0.6628\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - ETA: 0s - loss: 0.616 - 0s 54us/sample - loss: 0.6262 - val_loss: 0.6592\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.6227 - val_loss: 0.6556\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.6193 - val_loss: 0.6521\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.6160 - val_loss: 0.6489\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.6128 - val_loss: 0.6456\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.6097 - val_loss: 0.6423\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.6066 - val_loss: 0.6392\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.6037 - val_loss: 0.6362\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.6007 - val_loss: 0.6332\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.5979 - val_loss: 0.6303\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.5950 - val_loss: 0.6273\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.5924 - val_loss: 0.6245\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.5897 - val_loss: 0.6218\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.5871 - val_loss: 0.6191\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.5846 - val_loss: 0.6165\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.5820 - val_loss: 0.6139\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.5796 - val_loss: 0.6113\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.5772 - val_loss: 0.6088\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.5748 - val_loss: 0.6063\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.5724 - val_loss: 0.6039\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.5701 - val_loss: 0.6015\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.5679 - val_loss: 0.5992\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.5656 - val_loss: 0.5968\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.5635 - val_loss: 0.5945\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.5612 - val_loss: 0.5921\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.5591 - val_loss: 0.5899\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.5570 - val_loss: 0.5878\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.5549 - val_loss: 0.5855\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.5529 - val_loss: 0.5834\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.5509 - val_loss: 0.5813\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.5488 - val_loss: 0.5792\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.5469 - val_loss: 0.5772\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.5450 - val_loss: 0.5751\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5431 - val_loss: 0.5731\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.5412 - val_loss: 0.5711\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5394 - val_loss: 0.5691\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.5375 - val_loss: 0.5672\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.5357 - val_loss: 0.5652\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.5339 - val_loss: 0.5634\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.5322 - val_loss: 0.5614\n",
      "3870/3870 [==============================] - 0s 21us/sample - loss: 0.4911\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.5310\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 76us/sample - loss: 4.3679 - val_loss: 3.7153\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 2.9557 - val_loss: 2.6109\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 2.1629 - val_loss: 2.0181\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 1.7284 - val_loss: 1.6813\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 1.4659 - val_loss: 1.4584\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 1.2811 - val_loss: 1.2927\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 1.1416 - val_loss: 1.1652\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 1.0333 - val_loss: 1.0641\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.9473 - val_loss: 0.9844\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.8801 - val_loss: 0.9217\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.8280 - val_loss: 0.8726\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.7872 - val_loss: 0.8342\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.7551 - val_loss: 0.8037\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.7297 - val_loss: 0.7795\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.7093 - val_loss: 0.7601\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.6929 - val_loss: 0.7443\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.6793 - val_loss: 0.7309\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.6679 - val_loss: 0.7196\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.6580 - val_loss: 0.7098\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.6494 - val_loss: 0.7011\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.6416 - val_loss: 0.6935\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.6347 - val_loss: 0.6865\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.6284 - val_loss: 0.6800\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.6225 - val_loss: 0.6740\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.6170 - val_loss: 0.6683\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.6118 - val_loss: 0.6629\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.6069 - val_loss: 0.6578\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.6023 - val_loss: 0.6529\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.5978 - val_loss: 0.6482\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.5936 - val_loss: 0.6438\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.5894 - val_loss: 0.6395\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.5855 - val_loss: 0.6353\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.5816 - val_loss: 0.6313\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.5779 - val_loss: 0.6274\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.5742 - val_loss: 0.6236\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.5708 - val_loss: 0.6198\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.5674 - val_loss: 0.6163\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.5641 - val_loss: 0.6127\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.5609 - val_loss: 0.6093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.5579 - val_loss: 0.6059\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.5548 - val_loss: 0.6027\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.5519 - val_loss: 0.5995\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.5490 - val_loss: 0.5965\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.5462 - val_loss: 0.5935\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.5435 - val_loss: 0.5906\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.5409 - val_loss: 0.5877\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 1s 73us/sample - loss: 0.5383 - val_loss: 0.5850\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.5358 - val_loss: 0.5822\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.5334 - val_loss: 0.5796\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.5310 - val_loss: 0.5770\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.5286 - val_loss: 0.5744\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.5264 - val_loss: 0.5719\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.5242 - val_loss: 0.5694\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.5220 - val_loss: 0.5670\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.5199 - val_loss: 0.5647\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.5178 - val_loss: 0.5625\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.5158 - val_loss: 0.5603\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5138 - val_loss: 0.5581\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.5119 - val_loss: 0.5560\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.5100 - val_loss: 0.5539\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.5082 - val_loss: 0.5518\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.5064 - val_loss: 0.5499\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.5046 - val_loss: 0.5479\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.5029 - val_loss: 0.5459\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.5012 - val_loss: 0.5440\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.4996 - val_loss: 0.5421\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.4980 - val_loss: 0.5403\n",
      "3870/3870 [==============================] - 0s 21us/sample - loss: 0.5051\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.4969\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 77us/sample - loss: 3.9444 - val_loss: 3.2845\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 2.5505 - val_loss: 2.2026\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 1.8176 - val_loss: 1.6802\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 1.4427 - val_loss: 1.4052\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 1.2275 - val_loss: 1.2387\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 1.0853 - val_loss: 1.1228\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.9832 - val_loss: 1.0340\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.9059 - val_loss: 0.9655\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.8474 - val_loss: 0.9120\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.8023 - val_loss: 0.8699\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.7671 - val_loss: 0.8366\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.7393 - val_loss: 0.8101\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.7174 - val_loss: 0.7892\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.6999 - val_loss: 0.7722\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.6854 - val_loss: 0.7581\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.6733 - val_loss: 0.7460\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.6627 - val_loss: 0.7355\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.6536 - val_loss: 0.7262\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.6454 - val_loss: 0.7176\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.6377 - val_loss: 0.7096\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.6307 - val_loss: 0.7021\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.6241 - val_loss: 0.6950\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.6179 - val_loss: 0.6883\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.6119 - val_loss: 0.6820\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.6062 - val_loss: 0.6758\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.6008 - val_loss: 0.6698\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.5956 - val_loss: 0.6638\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.5904 - val_loss: 0.6582\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.5856 - val_loss: 0.6526\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.5808 - val_loss: 0.6472\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.5762 - val_loss: 0.6419\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.5717 - val_loss: 0.6369\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.5673 - val_loss: 0.6320\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.5630 - val_loss: 0.6272\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.5590 - val_loss: 0.6225\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.5549 - val_loss: 0.6179\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.5511 - val_loss: 0.6134\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.5473 - val_loss: 0.6090\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.5435 - val_loss: 0.6049\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.5399 - val_loss: 0.6006\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.5365 - val_loss: 0.5965\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.5330 - val_loss: 0.5925\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.5297 - val_loss: 0.5886\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.5264 - val_loss: 0.5847\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.5231 - val_loss: 0.5810\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.5200 - val_loss: 0.5773\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.5169 - val_loss: 0.5737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5139 - val_loss: 0.5701\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.5109 - val_loss: 0.5666\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.5080 - val_loss: 0.5632\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.5051 - val_loss: 0.5598\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5023 - val_loss: 0.5565\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4996 - val_loss: 0.5533\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.4969 - val_loss: 0.5502\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.4943 - val_loss: 0.5471\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.4917 - val_loss: 0.5441\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.4893 - val_loss: 0.5411\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.4868 - val_loss: 0.5382\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.4844 - val_loss: 0.5354\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.4820 - val_loss: 0.5326\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.4798 - val_loss: 0.5299\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.4775 - val_loss: 0.5273\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.4753 - val_loss: 0.5247\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.4731 - val_loss: 0.5221\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.4710 - val_loss: 0.5196\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.4690 - val_loss: 0.5171\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.4669 - val_loss: 0.5147\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.4649 - val_loss: 0.5123\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4630 - val_loss: 0.5100\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.4610 - val_loss: 0.5078\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.4592 - val_loss: 0.5056\n",
      "Epoch 72/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4574 - val_loss: 0.5035\n",
      "Epoch 73/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4556 - val_loss: 0.5014\n",
      "Epoch 74/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.4539 - val_loss: 0.4993\n",
      "Epoch 75/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.4522 - val_loss: 0.4973\n",
      "Epoch 76/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.4505 - val_loss: 0.4954\n",
      "Epoch 77/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.4489 - val_loss: 0.4935\n",
      "Epoch 78/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.4473 - val_loss: 0.4916\n",
      "Epoch 79/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.4457 - val_loss: 0.4898\n",
      "3870/3870 [==============================] - 0s 20us/sample - loss: 0.4855\n",
      "7740/7740 [==============================] - 0s 20us/sample - loss: 0.4446\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 81us/sample - loss: 1.4053 - val_loss: 0.7242\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 1s 75us/sample - loss: 0.6312 - val_loss: 0.6140\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.5616 - val_loss: 0.5567\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5192 - val_loss: 0.5167\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.4871 - val_loss: 0.4915\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.4631 - val_loss: 0.4669\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.4453 - val_loss: 0.4478\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.4303 - val_loss: 0.4378\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.4183 - val_loss: 0.4281\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4073 - val_loss: 0.4152\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3983 - val_loss: 0.4139\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3911 - val_loss: 0.3974\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3848 - val_loss: 0.3948\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 1s 138us/sample - loss: 0.3787 - val_loss: 0.3918\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.3735 - val_loss: 0.3852\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 1s 91us/sample - loss: 0.3688 - val_loss: 0.3788\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3647 - val_loss: 0.3791\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3609 - val_loss: 0.3716\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 1s 74us/sample - loss: 0.3574 - val_loss: 0.3700\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.3532 - val_loss: 0.3736\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 1s 87us/sample - loss: 0.3513 - val_loss: 0.3634\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 1s 83us/sample - loss: 0.3491 - val_loss: 0.3617\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3464 - val_loss: 0.3599\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3443 - val_loss: 0.3604\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3414 - val_loss: 0.3616\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3393 - val_loss: 0.3536\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.3377 - val_loss: 0.3523\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 1s 81us/sample - loss: 0.3360 - val_loss: 0.3507\n",
      "3870/3870 [==============================] - 0s 25us/sample - loss: 0.3316\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.3312\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 115us/sample - loss: 1.6661 - val_loss: 0.8188\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.6812 - val_loss: 0.6486\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 1s 77us/sample - loss: 0.5734 - val_loss: 0.5933\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.5328 - val_loss: 0.5558\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 65us/sample - loss: 0.5031 - val_loss: 0.5307\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 1s 74us/sample - loss: 0.4808 - val_loss: 0.5057\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.4610 - val_loss: 0.4882\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.4472 - val_loss: 0.4709\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4343 - val_loss: 0.4563\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.4234 - val_loss: 0.4456\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.4156 - val_loss: 0.4404\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4091 - val_loss: 0.4331\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4035 - val_loss: 0.4249\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.3973 - val_loss: 0.4194\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3928 - val_loss: 0.4145\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.3892 - val_loss: 0.4111\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 1s 151us/sample - loss: 0.3848 - val_loss: 0.4073\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.3807 - val_loss: 0.4038\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.3775 - val_loss: 0.4107\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.3743 - val_loss: 0.3949\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.3712 - val_loss: 0.3933\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3686 - val_loss: 0.3905\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3654 - val_loss: 0.3863\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3617 - val_loss: 0.3872\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.3587 - val_loss: 0.3821\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3566 - val_loss: 0.3797\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3538 - val_loss: 0.3756\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3516 - val_loss: 0.3721\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3493 - val_loss: 0.3709\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3465 - val_loss: 0.3695\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3447 - val_loss: 0.3679\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.3432 - val_loss: 0.3642\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3411 - val_loss: 0.3632\n",
      "3870/3870 [==============================] - 0s 23us/sample - loss: 0.3392\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3387\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 85us/sample - loss: 1.2810 - val_loss: 0.7476\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.6422 - val_loss: 0.6562\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.5706 - val_loss: 0.5951\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.5200 - val_loss: 0.5505\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.4815 - val_loss: 0.5137\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4509 - val_loss: 0.4806\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4280 - val_loss: 0.4616\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.4109 - val_loss: 0.4412\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3975 - val_loss: 0.4322\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3887 - val_loss: 0.4199\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3808 - val_loss: 0.4108\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3758 - val_loss: 0.4049\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3692 - val_loss: 0.3998\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3646 - val_loss: 0.3931\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3599 - val_loss: 0.3913\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3562 - val_loss: 0.3893\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3524 - val_loss: 0.3869\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3506 - val_loss: 0.3797\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3467 - val_loss: 0.3770\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3441 - val_loss: 0.3727\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3415 - val_loss: 0.3734\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3388 - val_loss: 0.3685\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3366 - val_loss: 0.3660\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3345 - val_loss: 0.3654\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3323 - val_loss: 0.3623\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3300 - val_loss: 0.3630\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3281 - val_loss: 0.3587\n",
      "3870/3870 [==============================] - 0s 22us/sample - loss: 0.3725\n",
      "7740/7740 [==============================] - 0s 21us/sample - loss: 0.3231\n",
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "11610/11610 [==============================] - 1s 70us/sample - loss: 1.1380 - val_loss: 0.6413\n",
      "Epoch 2/100\n",
      "11610/11610 [==============================] - 1s 51us/sample - loss: 0.5521 - val_loss: 0.5438\n",
      "Epoch 3/100\n",
      "11610/11610 [==============================] - 1s 51us/sample - loss: 0.4842 - val_loss: 0.4827\n",
      "Epoch 4/100\n",
      "11610/11610 [==============================] - 1s 51us/sample - loss: 0.4428 - val_loss: 0.4479\n",
      "Epoch 5/100\n",
      "11610/11610 [==============================] - 1s 51us/sample - loss: 0.4169 - val_loss: 0.4218\n",
      "Epoch 6/100\n",
      "11610/11610 [==============================] - 1s 51us/sample - loss: 0.3996 - val_loss: 0.4083\n",
      "Epoch 7/100\n",
      "11610/11610 [==============================] - 1s 52us/sample - loss: 0.3866 - val_loss: 0.3971\n",
      "Epoch 8/100\n",
      "11610/11610 [==============================] - 1s 52us/sample - loss: 0.3779 - val_loss: 0.4029\n",
      "Epoch 9/100\n",
      "11610/11610 [==============================] - 1s 53us/sample - loss: 0.3704 - val_loss: 0.3887\n",
      "Epoch 10/100\n",
      "11610/11610 [==============================] - 1s 51us/sample - loss: 0.3647 - val_loss: 0.3769\n",
      "Epoch 11/100\n",
      "11610/11610 [==============================] - 1s 52us/sample - loss: 0.3604 - val_loss: 0.3811\n",
      "Epoch 12/100\n",
      "11610/11610 [==============================] - 1s 65us/sample - loss: 0.3557 - val_loss: 0.3671\n",
      "Epoch 13/100\n",
      "11610/11610 [==============================] - 1s 53us/sample - loss: 0.3515 - val_loss: 0.3643\n",
      "Epoch 14/100\n",
      "11610/11610 [==============================] - 1s 52us/sample - loss: 0.3480 - val_loss: 0.3618\n",
      "Epoch 15/100\n",
      "11610/11610 [==============================] - 1s 52us/sample - loss: 0.3449 - val_loss: 0.3595\n",
      "Epoch 16/100\n",
      "11610/11610 [==============================] - 1s 53us/sample - loss: 0.3417 - val_loss: 0.3611\n",
      "Epoch 17/100\n",
      "11610/11610 [==============================] - 1s 54us/sample - loss: 0.3389 - val_loss: 0.3606\n",
      "Epoch 18/100\n",
      "11610/11610 [==============================] - 1s 52us/sample - loss: 0.3354 - val_loss: 0.3677\n"
     ]
    }
   ],
   "source": [
    "learning_rates = [1e-4,3*1e-4,1e-3,3*1e-3,1e-2,3*1e-2]\n",
    "\n",
    "def bulid_model(hidden_layers,layer_size,learning_rate):\n",
    "    model_keras = keras.models.Sequential();\n",
    "    model_keras.add(keras.layers.Dense(layer_size, activation='relu',\n",
    "                                       input_shape=x_train.shape[1:]))\n",
    "    for _ in range(hidden_layers-1):\n",
    "        model_keras.add(keras.layers.Dense(layer_size, activation='relu'))\n",
    "    model_keras.add(keras.layers.Dense(1))\n",
    "    optimizer = keras.optimizers.SGD(learning_rate)\n",
    "    model_keras.compile(loss=\"mse\", optimizer=optimizer)\n",
    "    return model_keras\n",
    "\n",
    "model = keras.wrappers.scikit_learn.KerasRegressor(bulid_model)\n",
    "\n",
    "params = {'hidden_layers' : np.arange(1,5),\n",
    "          'layer_size'   : np.arange(1,100),\n",
    "          'learning_rate': scipy.stats.reciprocal(1e-4,1e-2)}\n",
    "\n",
    "callbacks = [keras.callbacks.EarlyStopping(patience=5, min_delta=1e-2),\n",
    "             keras.callbacks.TensorBoard(log_dir='logs/regression-callbacks')]\n",
    "\n",
    "random_search_cv = sklearn.model_selection.RandomizedSearchCV(model,\n",
    "                                                              param_distributions=params,\n",
    "                                                              cv=3)\n",
    "\n",
    "history = random_search_cv.fit(x_train_scaled, y_train,\n",
    "                validation_data = (x_valid_scaled, y_valid),\n",
    "                epochs = 100,\n",
    "                callbacks = callbacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on RandomizedSearchCV in module sklearn.model_selection._search object:\n",
      "\n",
      "class RandomizedSearchCV(BaseSearchCV)\n",
      " |  RandomizedSearchCV(estimator, param_distributions, n_iter=10, scoring=None, fit_params=None, n_jobs=None, iid='warn', refit=True, cv='warn', verbose=0, pre_dispatch='2*n_jobs', random_state=None, error_score='raise-deprecating', return_train_score='warn')\n",
      " |  \n",
      " |  Randomized search on hyper parameters.\n",
      " |  \n",
      " |  RandomizedSearchCV implements a \"fit\" and a \"score\" method.\n",
      " |  It also implements \"predict\", \"predict_proba\", \"decision_function\",\n",
      " |  \"transform\" and \"inverse_transform\" if they are implemented in the\n",
      " |  estimator used.\n",
      " |  \n",
      " |  The parameters of the estimator used to apply these methods are optimized\n",
      " |  by cross-validated search over parameter settings.\n",
      " |  \n",
      " |  In contrast to GridSearchCV, not all parameter values are tried out, but\n",
      " |  rather a fixed number of parameter settings is sampled from the specified\n",
      " |  distributions. The number of parameter settings that are tried is\n",
      " |  given by n_iter.\n",
      " |  \n",
      " |  If all parameters are presented as a list,\n",
      " |  sampling without replacement is performed. If at least one parameter\n",
      " |  is given as a distribution, sampling with replacement is used.\n",
      " |  It is highly recommended to use continuous distributions for continuous\n",
      " |  parameters.\n",
      " |  \n",
      " |  Note that before SciPy 0.16, the ``scipy.stats.distributions`` do not\n",
      " |  accept a custom RNG instance and always use the singleton RNG from\n",
      " |  ``numpy.random``. Hence setting ``random_state`` will not guarantee a\n",
      " |  deterministic iteration whenever ``scipy.stats`` distributions are used to\n",
      " |  define the parameter search space.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <randomized_parameter_search>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  estimator : estimator object.\n",
      " |      A object of that type is instantiated for each grid point.\n",
      " |      This is assumed to implement the scikit-learn estimator interface.\n",
      " |      Either estimator needs to provide a ``score`` function,\n",
      " |      or ``scoring`` must be passed.\n",
      " |  \n",
      " |  param_distributions : dict\n",
      " |      Dictionary with parameters names (string) as keys and distributions\n",
      " |      or lists of parameters to try. Distributions must provide a ``rvs``\n",
      " |      method for sampling (such as those from scipy.stats.distributions).\n",
      " |      If a list is given, it is sampled uniformly.\n",
      " |  \n",
      " |  n_iter : int, default=10\n",
      " |      Number of parameter settings that are sampled. n_iter trades\n",
      " |      off runtime vs quality of the solution.\n",
      " |  \n",
      " |  scoring : string, callable, list/tuple, dict or None, default: None\n",
      " |      A single string (see :ref:`scoring_parameter`) or a callable\n",
      " |      (see :ref:`scoring`) to evaluate the predictions on the test set.\n",
      " |  \n",
      " |      For evaluating multiple metrics, either give a list of (unique) strings\n",
      " |      or a dict with names as keys and callables as values.\n",
      " |  \n",
      " |      NOTE that when using custom scorers, each scorer should return a single\n",
      " |      value. Metric functions returning a list/array of values can be wrapped\n",
      " |      into multiple scorers that return one value each.\n",
      " |  \n",
      " |      See :ref:`multimetric_grid_search` for an example.\n",
      " |  \n",
      " |      If None, the estimator's default scorer (if available) is used.\n",
      " |  \n",
      " |  fit_params : dict, optional\n",
      " |      Parameters to pass to the fit method.\n",
      " |  \n",
      " |      .. deprecated:: 0.19\n",
      " |         ``fit_params`` as a constructor argument was deprecated in version\n",
      " |         0.19 and will be removed in version 0.21. Pass fit parameters to\n",
      " |         the ``fit`` method instead.\n",
      " |  \n",
      " |  n_jobs : int or None, optional (default=None)\n",
      " |      Number of jobs to run in parallel.\n",
      " |      ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
      " |      ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
      " |      for more details.\n",
      " |  \n",
      " |  pre_dispatch : int, or string, optional\n",
      " |      Controls the number of jobs that get dispatched during parallel\n",
      " |      execution. Reducing this number can be useful to avoid an\n",
      " |      explosion of memory consumption when more jobs get dispatched\n",
      " |      than CPUs can process. This parameter can be:\n",
      " |  \n",
      " |          - None, in which case all the jobs are immediately\n",
      " |            created and spawned. Use this for lightweight and\n",
      " |            fast-running jobs, to avoid delays due to on-demand\n",
      " |            spawning of the jobs\n",
      " |  \n",
      " |          - An int, giving the exact number of total jobs that are\n",
      " |            spawned\n",
      " |  \n",
      " |          - A string, giving an expression as a function of n_jobs,\n",
      " |            as in '2*n_jobs'\n",
      " |  \n",
      " |  iid : boolean, default='warn'\n",
      " |      If True, return the average score across folds, weighted by the number\n",
      " |      of samples in each test set. In this case, the data is assumed to be\n",
      " |      identically distributed across the folds, and the loss minimized is\n",
      " |      the total loss per sample, and not the mean loss across the folds. If\n",
      " |      False, return the average score across folds. Default is True, but\n",
      " |      will change to False in version 0.21, to correspond to the standard\n",
      " |      definition of cross-validation.\n",
      " |  \n",
      " |      .. versionchanged:: 0.20\n",
      " |          Parameter ``iid`` will change from True to False by default in\n",
      " |          version 0.22, and will be removed in 0.24.\n",
      " |  \n",
      " |  cv : int, cross-validation generator or an iterable, optional\n",
      " |      Determines the cross-validation splitting strategy.\n",
      " |      Possible inputs for cv are:\n",
      " |  \n",
      " |      - None, to use the default 3-fold cross validation,\n",
      " |      - integer, to specify the number of folds in a `(Stratified)KFold`,\n",
      " |      - :term:`CV splitter`,\n",
      " |      - An iterable yielding (train, test) splits as arrays of indices.\n",
      " |  \n",
      " |      For integer/None inputs, if the estimator is a classifier and ``y`` is\n",
      " |      either binary or multiclass, :class:`StratifiedKFold` is used. In all\n",
      " |      other cases, :class:`KFold` is used.\n",
      " |  \n",
      " |      Refer :ref:`User Guide <cross_validation>` for the various\n",
      " |      cross-validation strategies that can be used here.\n",
      " |  \n",
      " |      .. versionchanged:: 0.20\n",
      " |          ``cv`` default value if None will change from 3-fold to 5-fold\n",
      " |          in v0.22.\n",
      " |  \n",
      " |  refit : boolean, or string default=True\n",
      " |      Refit an estimator using the best found parameters on the whole\n",
      " |      dataset.\n",
      " |  \n",
      " |      For multiple metric evaluation, this needs to be a string denoting the\n",
      " |      scorer that would be used to find the best parameters for refitting\n",
      " |      the estimator at the end.\n",
      " |  \n",
      " |      The refitted estimator is made available at the ``best_estimator_``\n",
      " |      attribute and permits using ``predict`` directly on this\n",
      " |      ``RandomizedSearchCV`` instance.\n",
      " |  \n",
      " |      Also for multiple metric evaluation, the attributes ``best_index_``,\n",
      " |      ``best_score_`` and ``best_params_`` will only be available if\n",
      " |      ``refit`` is set and all of them will be determined w.r.t this specific\n",
      " |      scorer.\n",
      " |  \n",
      " |      See ``scoring`` parameter to know more about multiple metric\n",
      " |      evaluation.\n",
      " |  \n",
      " |  verbose : integer\n",
      " |      Controls the verbosity: the higher, the more messages.\n",
      " |  \n",
      " |  random_state : int, RandomState instance or None, optional, default=None\n",
      " |      Pseudo random number generator state used for random uniform sampling\n",
      " |      from lists of possible values instead of scipy.stats distributions.\n",
      " |      If int, random_state is the seed used by the random number generator;\n",
      " |      If RandomState instance, random_state is the random number generator;\n",
      " |      If None, the random number generator is the RandomState instance used\n",
      " |      by `np.random`.\n",
      " |  \n",
      " |  error_score : 'raise' or numeric\n",
      " |      Value to assign to the score if an error occurs in estimator fitting.\n",
      " |      If set to 'raise', the error is raised. If a numeric value is given,\n",
      " |      FitFailedWarning is raised. This parameter does not affect the refit\n",
      " |      step, which will always raise the error. Default is 'raise' but from\n",
      " |      version 0.22 it will change to np.nan.\n",
      " |  \n",
      " |  return_train_score : boolean, optional\n",
      " |      If ``False``, the ``cv_results_`` attribute will not include training\n",
      " |      scores.\n",
      " |  \n",
      " |      Current default is ``'warn'``, which behaves as ``True`` in addition\n",
      " |      to raising a warning when a training score is looked up.\n",
      " |      That default will be changed to ``False`` in 0.21.\n",
      " |      Computing training scores is used to get insights on how different\n",
      " |      parameter settings impact the overfitting/underfitting trade-off.\n",
      " |      However computing the scores on the training set can be computationally\n",
      " |      expensive and is not strictly required to select the parameters that\n",
      " |      yield the best generalization performance.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  cv_results_ : dict of numpy (masked) ndarrays\n",
      " |      A dict with keys as column headers and values as columns, that can be\n",
      " |      imported into a pandas ``DataFrame``.\n",
      " |  \n",
      " |      For instance the below given table\n",
      " |  \n",
      " |      +--------------+-------------+-------------------+---+---------------+\n",
      " |      | param_kernel | param_gamma | split0_test_score |...|rank_test_score|\n",
      " |      +==============+=============+===================+===+===============+\n",
      " |      |    'rbf'     |     0.1     |       0.80        |...|       2       |\n",
      " |      +--------------+-------------+-------------------+---+---------------+\n",
      " |      |    'rbf'     |     0.2     |       0.90        |...|       1       |\n",
      " |      +--------------+-------------+-------------------+---+---------------+\n",
      " |      |    'rbf'     |     0.3     |       0.70        |...|       1       |\n",
      " |      +--------------+-------------+-------------------+---+---------------+\n",
      " |  \n",
      " |      will be represented by a ``cv_results_`` dict of::\n",
      " |  \n",
      " |          {\n",
      " |          'param_kernel' : masked_array(data = ['rbf', 'rbf', 'rbf'],\n",
      " |                                        mask = False),\n",
      " |          'param_gamma'  : masked_array(data = [0.1 0.2 0.3], mask = False),\n",
      " |          'split0_test_score'  : [0.80, 0.90, 0.70],\n",
      " |          'split1_test_score'  : [0.82, 0.50, 0.70],\n",
      " |          'mean_test_score'    : [0.81, 0.70, 0.70],\n",
      " |          'std_test_score'     : [0.01, 0.20, 0.00],\n",
      " |          'rank_test_score'    : [3, 1, 1],\n",
      " |          'split0_train_score' : [0.80, 0.92, 0.70],\n",
      " |          'split1_train_score' : [0.82, 0.55, 0.70],\n",
      " |          'mean_train_score'   : [0.81, 0.74, 0.70],\n",
      " |          'std_train_score'    : [0.01, 0.19, 0.00],\n",
      " |          'mean_fit_time'      : [0.73, 0.63, 0.43],\n",
      " |          'std_fit_time'       : [0.01, 0.02, 0.01],\n",
      " |          'mean_score_time'    : [0.01, 0.06, 0.04],\n",
      " |          'std_score_time'     : [0.00, 0.00, 0.00],\n",
      " |          'params'             : [{'kernel' : 'rbf', 'gamma' : 0.1}, ...],\n",
      " |          }\n",
      " |  \n",
      " |      NOTE\n",
      " |  \n",
      " |      The key ``'params'`` is used to store a list of parameter\n",
      " |      settings dicts for all the parameter candidates.\n",
      " |  \n",
      " |      The ``mean_fit_time``, ``std_fit_time``, ``mean_score_time`` and\n",
      " |      ``std_score_time`` are all in seconds.\n",
      " |  \n",
      " |      For multi-metric evaluation, the scores for all the scorers are\n",
      " |      available in the ``cv_results_`` dict at the keys ending with that\n",
      " |      scorer's name (``'_<scorer_name>'``) instead of ``'_score'`` shown\n",
      " |      above. ('split0_test_precision', 'mean_train_precision' etc.)\n",
      " |  \n",
      " |  best_estimator_ : estimator or dict\n",
      " |      Estimator that was chosen by the search, i.e. estimator\n",
      " |      which gave highest score (or smallest loss if specified)\n",
      " |      on the left out data. Not available if ``refit=False``.\n",
      " |  \n",
      " |      For multi-metric evaluation, this attribute is present only if\n",
      " |      ``refit`` is specified.\n",
      " |  \n",
      " |      See ``refit`` parameter for more information on allowed values.\n",
      " |  \n",
      " |  best_score_ : float\n",
      " |      Mean cross-validated score of the best_estimator.\n",
      " |  \n",
      " |      For multi-metric evaluation, this is not available if ``refit`` is\n",
      " |      ``False``. See ``refit`` parameter for more information.\n",
      " |  \n",
      " |  best_params_ : dict\n",
      " |      Parameter setting that gave the best results on the hold out data.\n",
      " |  \n",
      " |      For multi-metric evaluation, this is not available if ``refit`` is\n",
      " |      ``False``. See ``refit`` parameter for more information.\n",
      " |  \n",
      " |  best_index_ : int\n",
      " |      The index (of the ``cv_results_`` arrays) which corresponds to the best\n",
      " |      candidate parameter setting.\n",
      " |  \n",
      " |      The dict at ``search.cv_results_['params'][search.best_index_]`` gives\n",
      " |      the parameter setting for the best model, that gives the highest\n",
      " |      mean score (``search.best_score_``).\n",
      " |  \n",
      " |      For multi-metric evaluation, this is not available if ``refit`` is\n",
      " |      ``False``. See ``refit`` parameter for more information.\n",
      " |  \n",
      " |  scorer_ : function or a dict\n",
      " |      Scorer function used on the held out data to choose the best\n",
      " |      parameters for the model.\n",
      " |  \n",
      " |      For multi-metric evaluation, this attribute holds the validated\n",
      " |      ``scoring`` dict which maps the scorer key to the scorer callable.\n",
      " |  \n",
      " |  n_splits_ : int\n",
      " |      The number of cross-validation splits (folds/iterations).\n",
      " |  \n",
      " |  refit_time_ : float\n",
      " |      Seconds used for refitting the best model on the whole dataset.\n",
      " |  \n",
      " |      This is present only if ``refit`` is not False.\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  The parameters selected are those that maximize the score of the held-out\n",
      " |  data, according to the scoring parameter.\n",
      " |  \n",
      " |  If `n_jobs` was set to a value higher than one, the data is copied for each\n",
      " |  parameter setting(and not `n_jobs` times). This is done for efficiency\n",
      " |  reasons if individual jobs take very little time, but may raise errors if\n",
      " |  the dataset is large and not enough memory is available.  A workaround in\n",
      " |  this case is to set `pre_dispatch`. Then, the memory is copied only\n",
      " |  `pre_dispatch` many times. A reasonable value for `pre_dispatch` is `2 *\n",
      " |  n_jobs`.\n",
      " |  \n",
      " |  See Also\n",
      " |  --------\n",
      " |  :class:`GridSearchCV`:\n",
      " |      Does exhaustive search over a grid of parameters.\n",
      " |  \n",
      " |  :class:`ParameterSampler`:\n",
      " |      A generator over parameter settings, constructed from\n",
      " |      param_distributions.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      RandomizedSearchCV\n",
      " |      BaseSearchCV\n",
      " |      abc.NewBase\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.base.MetaEstimatorMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, estimator, param_distributions, n_iter=10, scoring=None, fit_params=None, n_jobs=None, iid='warn', refit=True, cv='warn', verbose=0, pre_dispatch='2*n_jobs', random_state=None, error_score='raise-deprecating', return_train_score='warn')\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from BaseSearchCV:\n",
      " |  \n",
      " |  decision_function(self, X)\n",
      " |      Call decision_function on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if ``refit=True`` and the underlying estimator supports\n",
      " |      ``decision_function``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      -----------\n",
      " |      X : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |  \n",
      " |  fit(self, X, y=None, groups=None, **fit_params)\n",
      " |      Run fit with all sets of parameters.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      \n",
      " |      X : array-like, shape = [n_samples, n_features]\n",
      " |          Training vector, where n_samples is the number of samples and\n",
      " |          n_features is the number of features.\n",
      " |      \n",
      " |      y : array-like, shape = [n_samples] or [n_samples, n_output], optional\n",
      " |          Target relative to X for classification or regression;\n",
      " |          None for unsupervised learning.\n",
      " |      \n",
      " |      groups : array-like, with shape (n_samples,), optional\n",
      " |          Group labels for the samples used while splitting the dataset into\n",
      " |          train/test set.\n",
      " |      \n",
      " |      **fit_params : dict of string -> object\n",
      " |          Parameters passed to the ``fit`` method of the estimator\n",
      " |  \n",
      " |  inverse_transform(self, Xt)\n",
      " |      Call inverse_transform on the estimator with the best found params.\n",
      " |      \n",
      " |      Only available if the underlying estimator implements\n",
      " |      ``inverse_transform`` and ``refit=True``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      -----------\n",
      " |      Xt : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Call predict on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if ``refit=True`` and the underlying estimator supports\n",
      " |      ``predict``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      -----------\n",
      " |      X : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |  \n",
      " |  predict_log_proba(self, X)\n",
      " |      Call predict_log_proba on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if ``refit=True`` and the underlying estimator supports\n",
      " |      ``predict_log_proba``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      -----------\n",
      " |      X : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |  \n",
      " |  predict_proba(self, X)\n",
      " |      Call predict_proba on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if ``refit=True`` and the underlying estimator supports\n",
      " |      ``predict_proba``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      -----------\n",
      " |      X : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |  \n",
      " |  score(self, X, y=None)\n",
      " |      Returns the score on the given data, if the estimator has been refit.\n",
      " |      \n",
      " |      This uses the score defined by ``scoring`` where provided, and the\n",
      " |      ``best_estimator_.score`` method otherwise.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape = [n_samples, n_features]\n",
      " |          Input data, where n_samples is the number of samples and\n",
      " |          n_features is the number of features.\n",
      " |      \n",
      " |      y : array-like, shape = [n_samples] or [n_samples, n_output], optional\n",
      " |          Target relative to X for classification or regression;\n",
      " |          None for unsupervised learning.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |  \n",
      " |  transform(self, X)\n",
      " |      Call transform on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if the underlying estimator supports ``transform`` and\n",
      " |      ``refit=True``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      -----------\n",
      " |      X : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from BaseSearchCV:\n",
      " |  \n",
      " |  classes_\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : boolean, optional\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x13a8b3350>\n",
      "4\n",
      "{'hidden_layers': 4, 'layer_size': 57, 'learning_rate': 0.002784457410995758}\n",
      "-0.3414070444565\n"
     ]
    }
   ],
   "source": [
    "print(history.best_estimator_)\n",
    "print(history.best_index_)\n",
    "print(history.best_params_)\n",
    "print(history.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5160/5160 [==============================] - 0s 29us/sample - loss: 0.3729\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3729351328324902"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = history.best_estimator_.model\n",
    "model.evaluate(x=x_test_scaled,y=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curves(history):\n",
    "    pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "    plt.grid(True)\n",
    "    plt.gca().set_ylim(0, 1)\n",
    "    plt.show()\n",
    "plot_learning_curves(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
